<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Swapnil Mallick' Homepage</title>

  <meta name="author" content="Xin Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Swapnil Mallick</name>
              </p>
              <hr>
              <p style="text-align:justify">Swapnil Mallick has recently graduated with a Master's degree in Computer Science from the <a href="https://www.cs.usc.edu/" target="_blank"> Thomas Lord Department of Computer Science </a> 
                at the <a href="https://www.usc.edu/" target="_blank">University of Southern California, Los Angeles</a>. Before joining USC, Swapnil completed Bachelor of Technology in Computer Science
                and Engineering from Maulana Abul Kalam Azad University of Technology (WBUT), West Bengal, India. </p>
              <p style="text-align:justify">As a graduate student at USC, Swapnil conducted research under the guidance of <a href="https://jdeshmukh.github.io/" target="_blank">Professor Jyotirmoy Vinay Deshmukh</a> at <a href="https://cps-vida.github.io/" target="_blank">UCS CPS-VIDA</a>
                on a project that addressed the safety monitoring of existing pedestrian detection systems in low-light weather conditions.
                Currently, he is continuing his research at USC under the guidance of Professor Deshmukh, focusing on scenario generation for comprehensive autonomous vehicle testing. 
                He is also collaborating with <a href="https://www.cs.unc.edu/~ronisen/" target="_blank">Professor Roni Sengupta</a> at the <a href="https://cv.cs.unc.edu/" target="_blank">UNC CV Group</a><a href="https://www.unc.edu/" target="_blank">, University of North Carolina at Chapel Hill</a> on a project to detect student video lecture engagement and live deep fakes using passive monitor illumination. </p>
              <p style="text-align:justify">He has also worked on a diverse range of projects as a graduate student at USC. 
                 He has partaken in a project that attempts to demonstrate the utility of social media data in monitoring public opinion regarding illegal rhino poaching and trade. Apart from that, he has engaged in projects related to multimodal approaches for human speech emotion recognition, 
                 designing an adaptive cruise control system for self-driving cars, few-shot image classification etc. As an undergraduate student, he has conducted research on detecting handwritten Bengali numerals under 
                 the supervision of <a href="https://scholar.google.co.in/citations?user=Sv_ONBAAAAAJ&hl=en" target="_blank">Professor Ujjwal Bhattacharya </a> at the <a href="https://www.isical.ac.in/~cvpr/CVPR-WebSite/index.html" target="_blank">Computer Vision and Pattern Recogntion Unit</a>, <a href="https://www.isical.ac.in/" target="_blank">Indian Statistical Institute, Kolkata, India</a>.  </p>
              <p style="text-align:justify">A detailed list of research experiences, publications and projects can be found below.</p>
		    
              <!-- <em> <font color="red"><strong>This website is currently under dvelopment!! Please come back later!</strong></font></em><br> -->
              <p style="text-align:center">
                <a href="mailto:smallick@usc.edu">Email</a> &nbsp/&nbsp
                <a href="" target="_blank">CV</a> &nbsp/&nbsp
                <!-- <a href="data/XinLiu-bio.txt" target="_blank">Bio</a> &nbsp/&nbsp */
                /* <a href="https://scholar.google.com/citations?hl=en&user=p9F83HoAAAAJ" target="_blank">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://x.com/Swapnil_897" target="_blank">Twitter</a> &nbsp/&nbsp
                <!-- <a href="https://github.com/xliucs/" target="_blank">Github</a> &nbsp/&nbsp */ -->
                <a href="https://www.linkedin.com/in/swapnil-mallick/" target="_blank">Linkedin</a>
              </p>

            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SWAPNIL_MALLICK_IMAGE.jpeg" target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SWAPNIL_MALLICK_IMAGE.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- Work Experience  -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" id="experience">
        <tr>
          <td>
          <heading>Research Experience</heading>
          </td>
        </tr>

        </table>
        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="padding-left: 20px;">
        <tr>
          <!-- UNC  -->
          <td width="12.5%" style="text-align: center;"><img src="images/UNC_LOGO.png" alt="unc_logo" width="200" height="60" valign="center"></td>
          <td> <span style="color:#1772d0; font-weight:bold"> <a href="https://cv.cs.unc.edu/" target="_blank">UNC CV Group</a>
            </span></td>
          <td> 

            <strong>Advisor:</strong> <a href="https://www.cs.unc.edu/~ronisen/" target="_blank">Prof. Roni Sengupta</a>
            <br>
            <em>(March, 2024 - Present)</em>
            <ul>
              <li style="text-align: justify;">Currently collaborating on detecting student video lecture engagement and live deep fakes with passive monitor illumination</li>
              <li style="text-align: justify;">Implemented a personalized ViT backbone architecture which shows a significant improvement in performance (74.95%) when compared with the previous architecture (62.05%) in dark lighting conditions</li>
              <li style="text-align: justify;">Experimenting with diffusion models and SDS loss (per-image optimization) to improve the monitor image prediction quality</li>
              <li style="text-align: justify;">Exploring the application of self and cross attention based architectures in detecting video engagement and live deep fakes with the ultimate goal of building a generalized model for the task</li>
            </ul> 
          </td>
        </tr>

        <tr>
          <!-- USC Scenario  -->
          <td width="12.5%" style="text-align: center;"><img src="images/USC_LOGO.png" alt="usc_logo" width="200" height="50" valign="center"></td>
          <td> <span style="color:#1772d0; font-weight:bold"> <a href="https://cps-vida.github.io/" target="_blank">USC CPS-VIDA</a>
            </span></td>
        
            <td> 
              
              <strong>Advisor:</strong> <a href="https://jdeshmukh.github.io/" target="_blank">Prof. Jyotirmoy Vinay Deshmukh</a>
              <br>
              <em>(March, 2024 - Present)</em>
              <ul>
                <li style="text-align: justify;">Currently working on a project on generating safety-critical scenarios for autonomous vehicle testing <strong>(RV '24)</strong></li>
                <li style="text-align: justify;">Explored Scenic to generate safety-critical scenarios</li>
                <li style="text-align: justify;">Broadly exploring the application of generative models like, VQGAN, diffusion models for generating safety-critical scenarios for comprehensive self-driving car testing</li>
              </ul> 
            </td>

        </tr>


        <!-- USC RV PAPER 1  -->
        <tr>
          <td width="12.5%" style="text-align: center;"><img src="images/USC_LOGO.png" alt="usc_logo" width="200" height="50" valign="center"></td>
          <td> <span style="color:#1772d0; font-weight:bold"> <a href="https://cps-vida.github.io/" target="_blank">USC CPS-VIDA</a>
            </span></td>

           <td> 
              
              <strong>Advisor:</strong> <a href="https://jdeshmukh.github.io/" target="_blank">Prof. Jyotirmoy Vinay Deshmukh</a>
              <br>
              <em>(May, 2023 - August, 2023)</em>
              <ul>
                <li style="text-align: justify;">Developed a safety monitoring framework for detecting the robustness of existing pedestrian detection models in low-light weather conditions using Timed Quality Temporal Logic (TQTL) <strong>(RV '23)</strong></li>
                <li style="text-align: justify;">Compared the robustness of vanilla YOLO and IA-YOLO in both foggy as well as night conditions</li>
                <li style="text-align: justify;">Proposed TQTL as a quality metric that will help in debugging or improving the existing pedestrian detection models</li>
              </ul> 
            </td>
        </tr>

        <!--  Internship  -->
        <tr>
          <td width="12.5%" style="text-align: center;"><img src="images/ISI_LOGO.png" alt="isical_logo" width="100" height="100" valign="center"></td>
          <td> <span style="color:#1772d0; font-weight:bold"> <a href="https://www.isical.ac.in/~cvpr/CVPR-WebSite/index.html" target="_blank">Computer Vision and Pattern Recogntion Unit</a>
            </span></td>

            <td> 
              
              <strong>Advisor:</strong> <a href="https://scholar.google.co.in/citations?user=Sv_ONBAAAAAJ&hl=en" target="_blank">Prof. Ujjwal Bhattacharya </a>
              <br>
              <em>(July, 2019 - May, 2020)</em>
              <br>
              <a href="/papers/ISI_CERTIFICATE.pdf" target="_blank">Internship Certificate</a>
              <ul>
                <li style="text-align: justify;">Designed three separate architectures for detecting handwritten Bengali numerals using Residual blocks, Inception blocks and LeNet-5 architecture</li>
                <li style="text-align: justify;">Employed DCGAN to create additional samples to deal with the initial scarcity of training data</li>
                <li style="text-align: justify;">Found that the simpler LeNet-5 architecture achieved a higher accuracy of ~ 98.2% on test data as compared to the architectures that used Inception block (~ 97.4%) and Residual block (~ 97.1%) </li>
              </ul> 
            </td>
        </tr>

        <!-- AI2 Internship  -->
        <!--<tr>
          <td width="12.5%" style="text-align: center;"><img src="images/ai2.png" alt="ai2_logo" width="70" height="60" valign="center"></td>
          <td> <span style="color:#1772d0; font-weight:bold"> <a href="https://allenai.org/" target="_blank">Allen Institute for AI</a>
            </span></td>
          <td>Intern</td>
          <td> <em>(June, 2019 - Sep, 2019)</em></td>
        </tr> -->
        </table>

        
        <!-- Research Experience  -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <!--<p>
 See a full-list of publication at my <a href="https://scholar.google.com/citations?user=p9F83HoAAAAJ&hl=en&authuser=1/" target="_blank">Google Scholar</a>. I publish papers under UW / Google. 
              </p>-->
            </td>
          </tr>
        </tbody></table>

        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <!-- <em> <font color="red"><strong> Not a full list. Under dvelopment!</strong></font></em><br> -->


	<!-- WACV Motion Paper -->
	<tr onmouseout="style_stop()" onmouseover="style_start()" >
	  <td width="25%">
	    <div class="one">
	    <div class="two" id = 'kudalkar2024rv'><img src='./papers/RRT_trees.png' style='width:210px;height:100px;'></div>
	    <img src='./papers/RRT_trees.png' style='width:128px;height:108px;'>
	    </div>
	    <script type="text/javascript">
	    function style_start() {
	    document.getElementById('papers/RRT_trees.png').style.opacity = "1";
	    }
	    function style_stop() {
	    document.getElementById('papers/RRT_trees.png').style.opacity = "0";
	    }
	    style_stop()
	    </script>
	  </td>
	  <td valign="top" width="75%">
		<papertitle> Sampling-based and Gradient-based Efficient Scenario Generation. </papertitle>
	<br>
	Vidisha Kudalkar, Navid Hashemi, Shilpa Mukhopadhyay, <strong>Swapnil Mallick</strong>, Christof Budnik, Parinitha Nagaraja, Jyotirmoy V. Deshmukh.
	 <br>
	      <em>Accepted at the 24th International Conference on Runtime Verification (RV '24)</em>
	      <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
	      <br>-->
	<br>
      <a href="https://easychair.org/smart-program/RV2024/2024-10-15.html#talk:266369" target="_blank">Abstract</a>
      /
	    <a href="">PDF (Coming Soon)</a>
	    /
	    <a href="">bibtex (Coming Soon)</a>
	  </td>
	</tr>


          <!-- rPPG Toolbox Paper -->
          <tr onmouseout="style_stop()" onmouseover="style_start()" >
            <td width="25%">
              <div class="one">
              <div class="two" id = 'mallick2023rv'><img src='./papers/TQTL_FOGGY.jpg' style='width:210px;height:100px;'></div>
              <img src='./papers/TQTL_FOGGY.jpg' style='width:128px;height:108px;'>
              </div>
              <script type="text/javascript">
              function style_start() {
              document.getElementById('papers/TQTL_FOGGY.jpg').style.opacity = "1";
              }
              function style_stop() {
              document.getElementById('papers/TQTL_FOGGY.jpg').style.opacity = "0";
              }
              style_stop()
              </script>
            </td>
            <td valign="top" width="75%">
                  <papertitle> Safety monitoring for pedestrian detection in adverse conditions. </papertitle>
          <br>
          <strong>Swapnil Mallick</strong>*, Shuvam Ghosal*, Anand Balakrishnan, Jyotirmoy Deshmukh. (<em>* denotes equal contribution</em>)<br>
                <em>23rd International Conference on Runtime Verification (RV '23)</em><br>
          <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-44267-4_22" target="_blank">Springer LNCS</a>
              /
              <a href="/papers/549158_1_En_22_Chapter_OnlinePDF.PDF" target="_blank">PDF</a>
              /
              <a href="/papers/10.1007_978-3-031-44267-4_22-citation.bib">bibtex</a>
            </td>
          </tr>

          <!-- Health Learner -->
          <!--<tr onmouseout="style_stop()" onmouseover="style_start()" >
            <td width="25%">
              <div class="one">
              <div class="two" id = 'liu2023large'><img src='./papers/liu2023large.png' style='width:210px;height:100px;'></div>
              <img src='./papers/liu2023large.png' style='width:128px;height:108px;'>
              </div>
              <script type="text/javascript">
              function style_start() {
              document.getElementById('papers/liu2023large.png').style.opacity = "1";
              }
              function style_stop() {
              document.getElementById('papers/liu2023large.png').style.opacity = "0";
              }
              style_stop()
              </script>
            </td>
            <td valign="top" width="75%">
                  <papertitle> Large Language Models are Few-Shot Health Learners </papertitle>
          <br>
          <strong>Xin Liu</strong>, Daniel McDuff, Geza Kovacs, Isaac Galatzer-Levy, Jacob Sunshine, Jiening Zhan, Ming-Zher Poh, Shun Liao, Paolo Di Achille, Shwetak Patel <br>
                <em>Arxiv, 2023</em><br>
          <br>
              <a href="https://arxiv.org/pdf/2305.15525.pdf" target="_blank">pdf</a>
              /
              <a href="papers/liu2023large.bib">bibtex</a>
            </td>
          </tr> -->

          
            </table>

            
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Academic Projects</heading>
                <!--<p>
   See a full-list of publication at my <a href="https://scholar.google.com/citations?user=p9F83HoAAAAJ&hl=en&authuser=1/" target="_blank">Google Scholar</a>. I publish papers under UW / Google. 
                </p>-->
              </td>
            </tr>
          </tbody></table>

          <hr>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <!-- Rhino Project -->
              <tr>
                <td valign="top" width="75%">
                <papertitle> Analysing Twitter Data on Rhino Conservation using Natural Language Processing </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">This study, conducted as group project for CSCI 461 at USC, was designed to demonstrate 
                    the utility of social media data in monitoring public opinion regarding illegal rhino poaching and trade</li>
                  <li style="text-align: justify;">Various toolkits, including Pattern, TextBlob, VADER, and Twitter-roBERTa-base, were utilized to gauge the 
                    sentiment expressed in the tweets; used SHAP values to interpret the behavior of the models/toolkits</li>
                  <li style="text-align: justify;">In parallel, topic modeling techniques such as LDA and BTM were applied to gain deeper insights into the 
                    prevalent discussion topics and identify the user categories participating in these conversations</li>
                  <li style="text-align: justify;">The exploratory data analysis conducted on rhino-related tweets revealed that the volume of such tweets exhibited
                     a comparative increase from 2014 to 2019, reaching a peak in 2018</li>
                  <li style="text-align: justify;">For assessing the sentiment of tweets in conservation-related discussions, the results obtained did not provide 
                    a clear indication of the effectiveness of relying on pretrained NLP tools</li>
                  <li style="text-align: justify;">The topic modeling analysis revealed a dual nature of discussions on rhinos, encompassing both general themes 
                    such as 'Poaching' and 'Horn/Ivory Trade', as well as event-specific topics like the 
                    'Last White Male Northern Rhino Extinction' and 'Horn Stealing/Veterinarian'</li>
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="/papers/CSCI_461_PROJECT_FINAL_REPORT.pdf" target="_blank">Project Report</a>
                </td>
              </tr>

              <!-- CHIP -->

              <tr>
                <td valign="top" width="75%">
                <papertitle> CHIP: Contrastive Hierarchical Image Pretraining </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">This study, conducted in group of four students as the course project of CSCI 566 at USC, 
                    proposed a few-shot three-level hierarchical contrastive loss-based classification model that can classify an object of any 
                    unseen animal class into a relatively general category in a hierarchically based classification</li>
                  <li style="text-align: justify;">The proposed model was trained on a subset of the ImageNet (ILSVRC-12) dataset containing only 
                    the animal classes (366 classes in total) with 1300 images in each class</li>
                  <li style="text-align: justify;">The trained model was evaluated on a dataset created by us that contained 20 unseen animal classes 
                    not present in the ImageNet dataset</li>
                  <li style="text-align: justify;">The trained model, evaluated on 20 unseen animal classes, could classify 14 of them to their correct 
                    parent and super parent class</li>
                  <!--<li style="text-align: justify;"></li>
                  <li style="text-align: justify;"></li>
                  <li style="text-align: justify;"></li>-->
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="/papers/CSCI_566_FINAL_REPORT.pdf" target="_blank">Project Report</a>
                </td>
              </tr>

              <!-- ADAS -->

              <tr>
                <td valign="top" width="75%">
                <papertitle> Adaptive Cruise Control System of Self-driving Car </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">Designed an adaptive cruise control system of a self-driving car using YOLOv5 model for object detection and Monodepth2 for distance estimation</li>
                  <li style="text-align: justify;">The Monodepth2 model was used to output a disparity map of the bounding box region of the detected lead car 
                    from which the value at the centroid position of the bounding box was taken to get the estimated distance</li>
                  <li style="text-align: justify;">This was then fed to the PID controller of the ego car, which has to maintain a safe distance to the lead car</li>
                  <li style="text-align: justify;">The system was tested in CARLA simulator Town 6 and the ego car was found to always maintain a safe distance to the lead car</li>
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="https://github.com/SwapnilMallick/Adaptive-Cruise-Control-CARLA" target="_blank">Code</a>
                </td>
              </tr> 

              <!-- Stock Price -->
              <tr>
                <td valign="top" width="75%">
                <papertitle> Stock Price Prediction of a Company using LSTM </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">Leveraged an LSTM architecture to predict the stock price of a company</li>
                  <li style="text-align: justify;">Measured the performance of the model using RSME score</li>
                  <li style="text-align: justify;">Received highest RMSE score of 7.25 on unknown test data after running five times</li>
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="https://github.com/SwapnilMallick/RNN-Stock-Prediction" target="_blank">Code</a>
                </td>
              </tr> 

              <!-- Speech Emotion-->

              <tr>
                <td valign="top" width="75%">
                <papertitle> A Multi-modal Approach to Speech Emotion Recognition </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">This study, conducted as the course project of CSCI 544 at USC, 
                    uses audio and text as modalities from the IEMOCAP dataset for human emotion recognition</li>
                  <li style="text-align: justify;">A VGG frame architecture was trained from scratch to detect emotions 
                    from audio and a pretrained BERT was finetuned to predict the emotions from text transcriptions</li>
                  <li style="text-align: justify;">The text-only and audio-only architectures were combined to design a 
                    multimodal architecture for emotion recognition</li>
                  <li style="text-align: justify;">The multimodal architecture achieved a considerably higher accuracy of 
                    76.9% as compared to the models that used either text (72.4%) or audio (47.8%) as the modality</li>
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="/papers/SPEECH_EMOTION_REPORT.pdf" target="_blank">Project Report</a>
                  /
                  <a href="https://github.com/SwapnilMallick/Multimodal-Speech_Emotion_Recognition/tree/main/CODE" target="_blank">Code</a>
                </td>
              </tr>

              <!-- Cipher Text-->

              <tr>
                <td valign="top" width="75%">
                <papertitle> Cipher Text Prediction using BiLSTM </papertitle>
                <br> 
                <ul>
                  <li style="text-align: justify;">Designed a binary classifier that can classify whether a piece of text is encoded or not</li>
                  <li style="text-align: justify;">Converted text into word embeddings and employed BiLSTM for classification task</li>
                  <li style="text-align: justify;">The classifier achieved ~ 87.5% accuracy on training data and ~ 85% accuracy on test data</li>
                </ul>     
                    <!--<br><em> <font color="red"><strong>Oral, Top 53 out of 2042 Submissions (Top 2.6%) </strong></font></em>
                    <br>-->
              <br>
                  <a href="https://github.com/SwapnilMallick/Cipher-Text-Classifier" target="_blank">Code</a>
                </td>
              </tr>

            </table>

            <!-- Coursework -->
            
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                <heading>Coursework</heading>
                </td>
              </tr>
            </table>

            <hr>

            <table width="100%" align="center" border="0" cellpadding="20">
              <tr>  
                <td>Machine Learning</td>
                <td>Deep Learning</td>
                <td>Autonomous Cyber-Physical Systems</td>
              </tr>
              <tr>
                <td>Applied NLP</td>
                <td>Information Retrieval and Web Search Engines</td>
                <td>AI for Sustainable Development</td>
              </tr>
              <tr>
                <td>Database Systems</td>
                <td>Foundations of AI</td>
                <td>Algorithms</td>
              </tr>
              <tr>
                <td>Operations Research</td>
                <td>Computer Networks</td>
                <td>Automata</td>
              </tr>
              <tr>
                <td>Operating Systems</td>
                <td>Information and Coding Theory</td>
                <td>Numerical Methods</td>
              </tr>
            </table>

            <!-- Skills -->

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                <heading>Skills</heading>
                </td>
              </tr>
            </table>

            <hr>

            <table width="100%" align="center" border="0" cellpadding="20">
              <tr>
                <td><strong>Programming:</strong></td>
                <td>Python, C, C++</td>
              </tr>
              <tr>
                <td><strong>ML Frameworks:</strong></td>
                <td>Keras, TensorFlow, PyTorch, scikit-learn</td>
              </tr>
              <tr>
                <td><strong>Data Visualization:</strong></td>
                <td>Matplotlib, seaborn</td>
              </tr>
              <tr>
                <td><strong>Database:</strong></td>
                <td>MySQL, PostgreSQL, MongoDB</td>
              </tr>
              <tr>
                <td><strong>Software Tools:</strong></td>
                <td>Anaconda, Jupyter Notebook, LaTeX, CARLA Simulator, KNIME, WEKA, RapidMiner, Tableau, Gurobi Optimization</td>
              </tr>
            </table>

            <!-- Certifications-->

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                <heading>Certifications</heading>
                </td>
              </tr>
            </table>

            <hr>

            <table width="100%" align="center" border="0" cellpadding="20">
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/dl_ai_logo.png" alt="dl_ai_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/DEEP_LEARNING_SPECIALIZATION.pdf" target="_blank">Deep Learning Specialization</a>
                <br>
                <ul>
                  <li><a href="/papers/DL_1.pdf" target="_blank">Neural Networks and Deep Learning</a></li>
                  <li><a href="/papers/DL_2.pdf" target="_blank">Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization</a></li>
                  <li><a href="/papers/DL_3.pdf" target="_blank">Structuring Machine Learning Projects</a></li>
                  <li><a href="/papers/DL_4.pdf" target="_blank">Convolutional Neural Networks</a></li>
                  <li><a href="/papers/DL_5.pdf" target="_blank">Sequence Models</a></li>
                </ul></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/dl_ai_logo.png" alt="dl_ai_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/NLP_SPECIALIZATION.pdf" target="_blank">Natural Language Processing Specialization</a>
                  <br>
                  <ul>
                    <li><a href="/papers/NLP_1.pdf" target="_blank">Natural Language Processing with Classification and Vector Spaces</a></li>
                    <li><a href="/papers/NLP_2.pdf" target="_blank">Natural Language Processing with Probabilistic Models</a></li>
                    <li><a href="/papers/NLP_3.pdf" target="_blank">Natural Language Processing with Sequence Models</a></li>
                    <li><a href="/papers/NLP_4.pdf" target="_blank">Natural Language Processing with Attention Models</a></li>
                  </ul></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/vanderbilt_logo.jpg" alt="van_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/MATLAB.pdf" target="_blank">MATLAB</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/ucsc.jpg" alt="ucsc_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/BAYESIAN_STATISTICS.pdf" target="_blank">Bayesian Statistics</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/ucsd_logo.png" alt="ucsd_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/BIG_DATA_INTRO.pdf" target="_blank">Introduction to Big Data</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/ucsd_logo.png" alt="ucsd_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/BIG_DATA_INTEGRATION.pdf" target="_blank">Big Data Integration and Processing</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/ucsd_logo.png" alt="ucsd_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/BIG_DATA_MODELING.pdf" target="_blank">Big Data Modeling and Management Systems</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/ucsd_logo.png" alt="ucsd_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/ML_BIG_DATA.pdf" target="_blank">Machine Learning with Big Data</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/dl_ai_logo.png" alt="dl_ai_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/TENSORFLOW_INTRO.pdf" target="_blank">Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</a></td>
              </tr>
              <tr>
                <td width="12.5%" style="text-align: center;"><img src="images/dl_ai_logo.png" alt="dl_ai_logo" width="200" height="50" valign="center"></td>
                <td><a href="/papers/TENSORFLOW_CNN.pdf" target="_blank">Convolutional Neural Networks in TensorFlow</a></td>
              </tr>
            </table>



            <!-- Teaching Experience  -->

            <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
              <heading>Teaching Experience</heading>
              </td>
            </tr>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
            <tr>
              <td width="75%" valign="center">
              <p>
                Winter 2021/2022 - TECHIN 513: Managing Data and Signal Processing, Graduate Teaching Assistant
                <br>
                <br>
                Fall 2017 - CS328: Mobile Health & Sensing, Undergraduate Course Assistant <br>
                <em> <font color="red"><strong>Outstanding Course Assistant Award</strong></font></em>
                <br>
              </p>
              </td>
            </tr>
            </table>  -->

            <!-- MISC  -->

            <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
              <heading>Misc.</heading>
              </td>
            </tr>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
            <tr>
              <td width="75%" valign="center">
              <p>
                During my undergraduate studies, I spent a huge amount of effort to push the international community to engage various leadership experiences at the university.  I was the first international peer mentor in the residential life office and the first international student consultant in the department of information and technology. I worked at six different departments during my undergrd years :p
              </p>
                <p>
                During my free time, I enjoy snowboarding, climbing and playing tennis with my partner. I am also a big fan of NBA.
              </p>
              </td>
            </tr>
            </table>-->
            <!-- Credits  -->

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
              <br>
              <p align="right">
                <font size="2">
                Website Credits to Jon Barron <a href="https://github.com/jonbarron/jonbarron_website"><strong>source code</strong></a> and Siddhartha Gairola <a href="https://github.com/sidgairo18/sidgairo18.github.io"><strong>source code</strong></a>
                <br>
                <br>
                <a href="https://clustrmaps.com/site/1bof3"  title="Visit tracker"><img src="https://clustrmaps.com/map_v2.png?d=_c7s3tBLJ_u7PFZGsisO1FwUwEDTW0z1Xx_0zRnk25U&cl=ffffff" /></a>
      	  </font>
              </p>
              </td>
            </tr>
            </table>


          </td>
          </tr>
        </table>
        </body>
      </html>
