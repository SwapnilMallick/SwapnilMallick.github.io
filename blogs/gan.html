<html>
  <head>
    <!-- See http://docs.mathjax.org/en/latest/web/start.html#using-mathjax-from-a-content-delivery-network-cdn -->
    <title>Scenario Generation</title>

    <meta name="author" content="Swapnil Mallick">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
      <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.js"></script>
  </head>
<body>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <h1>A Guide To Generative Adversarial Network</h1>
    <h4>Date: August 29, 2024 | Estimated Reading Time: 15-20 min | Author: Swapnil Mallick </h4>
</div>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: x-large;">
<strong style="font-size: x-large;">Introduction</strong></p>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    Generative models have gained considerable attention in the field of unsupervised learning via Generative Adversarial Networks (GAN) due to 
    their outstanding data generation capability. Arguably their most significant impact has been in plausible image generation, image-to-image 
    translation, facial attribute manipulation, human language and music. It all started with the paper "Generative Adversarial Networks" 
    written by Goodfellow et al. in the year 2014. This paper is very well written and it tries to convince the readers that the method proposed 
    is sound mathematically. It proposes a framework for estimating generative models via an adversarial process, in which two models are 
    simultaneously trained - a generative model \(G\) that captures the data distribution, and a discriminative model \(D\) that estimates the 
    probability that a sample came from the training data rather than \(G\). 
</p>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    In simpler words, the job of the generator \(G\) is to generate synthetic samples given a noise variable input \(z\). On the other hand, 
    the discriminator \(D\) acts as a critic by trying to tell if a sample came from the real data distribution or was generated by the 
    generator \(G\). So, we can see that the discriminator is nothing but a simple binary classifier. By then, people already knew how to 
    build good image classifiers because this paper came shortly before the ResNet paper. However, this whole concept of a generator and 
    a discriminator and the way they were being used was very new at that time. Before GAN's came into the picture, generative networks 
    were not really prevalent. Mostly, compositional models and autoencoders were being used which would only generate blurry images along 
    with deep belief networks which also had their own problems. So, there was not really a satisfactory solution to the image generation 
    problem that would output high quality synthetic images. So the main underlying idea of this paper was - instead of trying to build 
    good generators, the authors wanted to harness the power of building good image classifiers, in this case discriminators, which would 
    help in training the generator and make it better at generating better images. Another novel idea was that the generator is not 
    trained using the data which was the case in other existing generative models like, autoencoders. Instead, the philosophy here is 
    to use the power of the discriminative model as classifiers in order to train the generator.
</p>

<p>
    <br>
</p>
</div>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Building Blocks of a GAN</strong>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    A GAN consists of two separate models: the generator and the discriminator.
    <ul>
        <li>A generator \(G\) outputs synthetic samples given a noise variable input \(z\). It is trained to capture the real data 
            distribution so that its generative samples can be as real as possible.</li>
        <li>A discriminator \(D\) estimates the probability of a given sample coming from the real dataset. It works as a critic and is 
            optimized to tell the fake samples from the real ones.</li>
    </ul>
</p>

<p>
<figure style="text-align: center;">
<img src="gan_architecture.png" alt="GAN Architecture" width=70% height="auto">
    <figcaption><strong>Figure 1. </strong> of a generative adversarial network.</figcaption>
</figure>
</p>
<p>
    <br>
</p>
</div>

<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Training a GAN</strong>
<p style="text-align: justify;">
    
</p>
<p style="text-align: justify;">
    <figure style="text-align: center;">
        <img src="forward_process.png" alt="Diffusion Forward Process" width=70% height="auto">
            <figcaption><strong>Figure 2.</strong> Change in data distribution in the forward diffusion process</figcaption>
    </figure>
</p>
<p style="text-align: justify;">
    
</p>
<p style="text-align: justify;">
    
</p>
<p style="text-align: justify;">
    
</p>
<p style="text-align: justify;">
    
</p>
<p style="text-align: justify;">
    
</p>
<p>
    <br>
</p>
</div>

<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Optimal Generator and Discriminator</strong>
<p style="text-align: justify;">
    
</p>
<p><br></p>
</div>


<p><br></p>
</div>


<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">References</strong>
<p style="text-align: justify;">[1] Merrill I Skolnik. ‚ÄúIntroduction to radar‚Äù. In: Radar handbook 2 (1962), p. 21.</p>
<p style="text-align: justify;">[2] Nadav Levanon. ‚ÄúRadar principles‚Äù. In: New York (1988).</p>
<p style="text-align: justify;">[3] Dean A Pomerleau. ‚ÄúAlvinn: An autonomous land vehicle in a neural network‚Äù. In: Advances 
    in neural information processing systems 1 (1988).</p>
<p style="text-align: justify;">[4] Douglas W Gage. UGV history 101: A brief history of Unmanned Ground Vehicle (UGV)
    development efforts. Naval Ocean Systems Center San Diego, CA, USA, 1995.</p>
<p style="text-align: justify;">[5] Sepp Hochreiter and J¬®urgen Schmidhuber. ‚ÄúLong short-term memory‚Äù. In: Neural computation
    9.8 (1997), pp. 1735‚Äì1780.</p>
</div>


</body>
</html>