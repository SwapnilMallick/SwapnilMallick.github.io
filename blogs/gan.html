<html>
  <head>
    <!-- See http://docs.mathjax.org/en/latest/web/start.html#using-mathjax-from-a-content-delivery-network-cdn -->
    <title>Scenario Generation</title>

    <meta name="author" content="Swapnil Mallick">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
      <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js@1.0.0/src/bibtex_js.js"></script>
  </head>
<body>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <h1>A Guide To Generative Adversarial Network</h1>
    <h4>Date: August 29, 2024 | Estimated Reading Time: 15-20 min | Author: Swapnil Mallick </h4>
</div>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size: x-large;">
<strong style="font-size: x-large;">Introduction</strong></p>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    Generative models have gained considerable attention in the field of unsupervised learning via Generative Adversarial Networks (GAN) <strong style="color: blue;">[1]</strong> due to 
    their outstanding data generation capability. Arguably their most significant impact has been in plausible image generation, image-to-image 
    translation, facial attribute manipulation, human language and music. It all started with the paper "Generative Adversarial Networks" 
    written by Goodfellow et al. in the year 2014 <strong style="color: blue;">[2]</strong>. This paper is very well written and it tries to convince the readers that the method proposed 
    is sound mathematically. It proposes a framework for estimating generative models via an adversarial process, in which two models are 
    simultaneously trained - a generative model \(G\) that captures the data distribution, and a discriminative model \(D\) that estimates the 
    probability that a sample came from the training data rather than \(G\). 
</p>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    In simpler words, the job of the generator \(G\) is to generate synthetic samples given a noise variable input \(z\). On the other hand, 
    the discriminator \(D\) acts as a critic by trying to tell if a sample came from the real data distribution or was generated by the 
    generator \(G\). So, we can see that the discriminator is nothing but a simple binary classifier. By then, people already knew how to 
    build good image classifiers because this paper came shortly before the ResNet <strong style="color: blue;">[3]</strong> paper. However, this whole concept of a generator and 
    a discriminator and the way they were being used was very new at that time. Before GAN's came into the picture, generative networks 
    were not really prevalent. Mostly, Boltzmann machines <strong style="color: blue;">[4]</strong> and autoencoders <strong style="color: blue;">[5]</strong> were being used which would only generate blurry images along 
    with deep belief networks <strong style="color: blue;">[6]</strong> which also had their own problems. So, there was not really a satisfactory solution to the image generation 
    problem that would output high quality synthetic images. So the main underlying idea of this paper was - instead of trying to build 
    good generators, the authors wanted to harness the power of building good image classifiers, in this case discriminators, which would 
    help in training the generator and make it better at generating better images. Another novel idea was that the generator is not 
    trained using the data which was the case in other existing generative models like, autoencoders. Instead, the philosophy here is 
    to use the power of the discriminative model as classifiers in order to train the generator.
</p>

<p>
    <br>
</p>
</div>
<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Building Blocks of a GAN</strong>
<p style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;text-align: justify;">
    A GAN consists of two separate models: the generator and the discriminator.
    <ul>
        <li>A generator \(G\) outputs synthetic samples given a noise variable input \(z\). It is trained to capture the real data 
            distribution so that its generative samples can be as real as possible.</li>
        <li>A discriminator \(D\) estimates the probability of a given sample coming from the real dataset. It works as a critic and is 
            optimized to tell the fake samples from the real ones.</li>
    </ul>
</p>

<p>
<figure style="text-align: center;">
<img src="gan_architecture.png" alt="GAN Architecture" width=70% height="auto">
    <figcaption><strong>Figure 1. </strong>Architecture of a generative adversarial network.</figcaption>
</figure>
</p>
<p>
    <br>
</p>
</div>

<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Training a GAN</strong>
<p style="text-align: justify;">
    Since we have discussed the components of a GAN, let us now see how to train the two models. 
    The authors of the paper use the following value function to optimize them,

    $$
    \begin{aligned}
    \min_G \max_D V(D, G) 
    & = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))] \\
    \end{aligned}
    $$
</p>

<p style="text-align: justify;">
    The discriminator improves by continuously trying to maximize this value function while the generator improves by trying 
    to minimize the function, again acting as each other's adversaries in this minimax game. Thinking in terms of iterations, 
    we update the discriminator by maximizing this objective starting from random initializations. Then with the updated 
    discriminator, the generator tries to minimize this objective. Now with the updated generator, the discriminator again 
    tries is to maximize this objective and this process keeps on repeating.
</p>
<p style="text-align: justify;">
    Rather than trying to dissect this objective, let us see what is happening if we just train these models on the classification 
    objectives that they have and that will give us a better understanding of this objective. At first, we look at the discriminator 
    which is trying to learn how to classify the input images as real or fake. We could turn this into a binary classification 
    task with the real images having ground truth label as one and fake images having ground truth label as zero and the network 
    could predict the probability of a given image being real or not. Then we could train the discriminator with the ground 
    truth labels and the predictions. The binary cross entropy loss can be written as follows,

    $$
    \begin{aligned} 
    \operatorname{loss}_d & =-\left(\frac{1}{N} \sum_{i=1}^N y_i \log \left(p_i\right)+\left(1-y_i\right) \log \left(1-p_i\right)\right)
    \end{aligned}
    $$

    ; where \(y_i\) is the ground truth label (either 0 or 1) and \(p_i\) is the prediction made by the discriminator (or the classifier) 
    for the \(i^{th}\) input. Let us rewrite the the BCE loss term as following for the ease of our own understanding,

    $$
    \begin{aligned}
        \operatorname{loss}_d & =-\left(\frac{1}{N} \sum_{i=1}^N y_i \log \left(D\left(\text {image}_i\right)\right)+\left(1-y_i\right) \log \left(1-D\left(\text {image}_i\right)\right)\right)
    \end{aligned}
    $$

    Now since for real images the label \(y_i\) will be 1, hence only the first term will remain and the second will vanish 
    because \((1 - y_i)\) will be 0. Similarly for fake images, only the second term would remain as \(y_i\) will be 0. So we 
    can express the term as,

    $$
    \begin{aligned} 
    \operatorname{loss}_d & =-\left(\frac{1}{N_{\text {real}}} \sum_i \log \left(D\left(x_i\right)\right)+\frac{1}{N_{\text {fake}}} \sum_i \log \left(1-D\left(G\left(z_i\right)\right)\right)\right)
    \end{aligned}
    $$

    ; where \(x_i\) is an instance of real image and \(z_i\) is a random noise sample and \(G(z_i)\) is the fake image that the generator 
    returns for that particular sample. 

</p>
<p style="text-align: justify;">
    In order to make our discriminator (or classifier) better, we need to minimize our loss and write it as,

    $$
    \begin{aligned} 
    \min\operatorname{loss}_d & =-\left(\frac{1}{N_{\text {real}}} \sum_i \log \left(D\left(x_i\right)\right)+\frac{1}{N_{\text {fake}}} \sum_i \log \left(1-D\left(G\left(z_i\right)\right)\right)\right)
    \end{aligned}
    $$

    Instead of minimizing the loss, we can achieve the same thing by maximizing the negative of this loss term and rewrite it as,

    $$
    \begin{aligned} 
    \max\operatorname{loss}_d & =\left(\frac{1}{N_{\text {real}}} \sum_i \log \left(D\left(x_i\right)\right)+\frac{1}{N_{\text {fake}}} \sum_i \log \left(1-D\left(G\left(z_i\right)\right)\right)\right)
    \end{aligned}
    $$

    This is now exactly what our objective also does, with the only difference being that sum replaced by expectation. 
    This is because we never have access to the entire distribution and only have access to certain number of samples from this 
    data distribution. If we assume that the sampling process is according to the probability distribution, then training with 
    the objective the authors mention and training with the binary cross entropy loss would be the same. 

</p>
<p style="text-align: justify;">
    For the discriminator, we would simply be training it to give higher probabilities for real images and lower probabilities 
    for fake images. So for the generator, we could say that since the generator is the adversary of the discriminator we must 
    train it with the opposite objective. This means that since the discriminator maximizes this function generator must minimize 
    it. But from the same classification perspective, we can also arrive at the following formulation,

    $$
    \begin{aligned}
    \min_G \max_D V(D, G) 
    & = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))] \\
    \end{aligned}
    $$

    The generator wants to minimize the probability of the  discriminator thinking that the generated sample is fake. 
    If you would have to improve the discriminator, we would have minimized the binary cross entropy loss between fake label 
    and the generated sample, BCE\((D(G(z)), 0)\). Hence for improving the generator, we can maximize BCE\((D(G(z)), 0)\) or minimize 
    the negative of this term and and the first quantity \(\mathbb{E}_{x \sim p_{data}(x)} [\log D(x)]\) is doing nothing here 
    because as far as optimizing the generator is concerned this is constant.
</p>
<p style="text-align: justify;">
    Now we said that we want to minimize this objective for the generator and we saw that this is is equivalent to maximizing BCE\((D(G(z)), 0)\) 
    which is the BCE loss with zero label for the discriminator output on generated sample. When you plot the \(log(1 - x)\) graph, you will 
    see that in regions where the discriminator gives lower probabilities the gradient is very small in terms of absolute value. But at 
    the start of the minimax game, the discriminator will indeed give very low probabilities for fake images because it will easily learn 
    to distinguish between the real images and the fake nonsensical samples. This is actually when the generator will need to improve using 
    the gradient of this loss but that becomes an issue because of the weaker gradients in this region. 
</p>

<p>
    <figure style="text-align: center;">
    <img src="log_1.png" alt="Log(1-x) plot" width=40% height="auto">
        <figcaption><strong>Figure 2. </strong>Plot of log(1-x).</figcaption>
    </figure>
</p>

<p style="text-align: justify;">
    Instead, the authors optimize using the \(log(x)\) function. Two things to note regarding this are: first, minimizing \(log(1 - x)\) 
    is same as maximizing \(log(x)\) in the 0 to 1 range which is what we are working with here and second, the gradient for the initial 
    iterations where discriminator gives lower probability to the generated sample is now much stronger and of higher absolute value. 
    Hence instead of minimizing \(\min_G \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))]\), it is better to have the generator 
    maximize \( \max_G \mathbb{E}_{z \sim p_z(z)} [\log(D(G(z)))]\). This is again exactly the same as minimizing BCE but with label 
    one for the discriminator output on generated sample. So ultimately instead of trying to minimize the likelihood of the discriminator 
    predicting the generated sample as fake, we are trying to maximize the likelihood of the discriminator predicting the generated sample as real.
</p>

<p>
    <figure style="text-align: center;">
    <img src="log_2.png" alt="Log(x) Plot" width=40% height="auto">
        <figcaption><strong>Figure 3. </strong>Plot of log(x).</figcaption>
    </figure>
</p>

<p>
    <br>
</p>
</div>

<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">Optimal Generator and Discriminator</strong>
<p style="text-align: justify;">
    The authors also prove the optimal point of this minimax game. Intuitively, what we desire is that the generated sample be exactly 
    same as the real samples but when that happens the discriminator will be confused because it cannot distinguish between them so it 
    will end up randomly classifying images as real or fake and will have 0.5 as the prediction probabilities.

    $$
    \begin{aligned}
        &\text{Optimal Generator} \implies p_{data} = p_{generated} \\
        &\text{Optimal Discriminator} \implies D(x) = D(G(z)) = \frac{1}{2}
    \end{aligned}  
    $$

    First let us rewrite the GAN objective below,

    $$
    \begin{aligned}
    \min_G \max_D V(D, G) 
    & = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))] \\
    \end{aligned}
    $$

    Now let us see if optimizing the GAN objective allows us to reach there. We will first try to find the optimal discriminator. 
    When we take sample \(z\) from the normal distribution \(p(z)\) and feed it to the generator, it will return an image which we 
    call \(G(z)\). Continuing this process for the entire distribution of noise samples will give us a distribution of images in 
    the image space. Let us call this \(p_g(x)\). Generated images that are mappings of highly probable \(z\)'s in the normal distribution 
    will have high probabilities in this \(p_g(x)\) distribution. Now let us go back to the objective and rewrite it as,

    $$
    \begin{aligned}
    \min_G \max_D V(D, G) 
    & = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{x \sim p_g(x)} [\log(1 - D(G(z)))] \\
    \end{aligned}
    $$

    All we are doing here is changing the random variable from \(z\) to \(G(z)\) and hence for computing the expectation, 
    instead of using \(p_z\), we are using the distribution of this new variable which is the distribution that we get by 
    passing noise sample \(z\) through the generator which we have termed as \(p_g\). Now, we can rewrite the expression as,

    $$
    \begin{aligned} 
    & \int_x p_{data}(x) \log (D(x))+\int_x p_g(x) \log (1-D(x)) \\ 
    & = \int_x p_{data}(x) \log (D(x))+p_g(x) \log (1-D(x))
    \end{aligned}
    $$

    Let, \(\tilde{x} = D(x), A=p_{data}(x), \text{and } B=p_g(x)\)

</p>

<p style="text-align: justify;">
    Then by replacing these we get,

    $$
    \begin{aligned}
        f(\tilde{x}) 
        & = A log\tilde{x} + B log(1-\tilde{x}) \\
        \frac{d f(\tilde{x})}{d \tilde{x}}
        & = A \frac{1}{ln10} \frac{1}{\tilde{x}} - B \frac{1}{ln10} \frac{1}{1 - \tilde{x}} \\
        & = \frac{1}{ln10} (\frac{A}{\tilde{x}} - \frac{B}{1-\tilde{x}}) \\
        & = \frac{1}{ln10} \frac{A - (A + B)\tilde{x}}{\tilde{x} (1 - \tilde{x})} \\
    \end{aligned}
    $$

    By setting \(\frac{d f(\tilde{x})}{d \tilde{x}} = 0\), we get the optimal discriminator,

    $$
    \begin{aligned}
        D^*(x) = \tilde{x}^* = \frac{A}{A + B} = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \in [0, 1]
    \end{aligned}
    $$

    When \(p_{data}(x) = 0, D^*(x) = 0\) <br>
    When \(p_{data}(x) >> p_g(x), D^*(x) = 1\) <br>
    When \(p_{data}(x) \approx p_g(x), D^*(x) = \frac{1}{2}\)
</p>

<p style="text-align: justify;">
When both the generator and discriminator are at optimal values, we have \(p_{data}(x) \approx p_g(x) \text{and} D^*(x) = \frac{1}{2}\). 
In that case, the loss function becomes,

$$
    \begin{aligned}
        &\int_x \bigg( p_{data}(x) \log(D^*(x)) + p_g (x) \log(1 - D^*(x)) \bigg) dx \\
        &= \log \frac{1}{2} \int_x p_{data}(x) dx + \log \frac{1}{2} \int_x p_g(x) dx \\
        &= -2\log2 \\
        &= -\log4
    \end{aligned}
$$

Now given this is what the optimal discriminator is, let us see what we get by trying to find the optimal generator once the 
discriminator is the optimal one. In that case, the value function can be reduced as follows,

$$
    \begin{aligned}
        &\int_x \bigg( p_{data}(x) \log(D^*(x)) + p_g (x) \log(1 - D^*(x)) \bigg) dx \\
        &= \log 4-\log 4+\int_x p_{\text {data }}(x) \log \left(\frac{p_{\text {data }}(x)}{p_{\text {data }}(x)+p_g(x)}\right)+\int_x p_g(x) \log \left(\frac{p_g(x)}{p_{\text {data }}(x)+p_g(x)}\right) \\ 
        &= -\log 4+\log 2+\log 2+\int_x p_{\text {data }}(x) \log \left(\frac{p_{\text {data }}(x)}{p_{\text {data }}(x)+p_g(x)}\right)+\int_x p_g(x) \log \left(\frac{p_g(x)}{p_{\text {data }}(x)+p_g(x)}\right) \\
        &= -\log 4 + \int_x p_{\text {data }}(x) \log \left(\frac{p_{\text {data }}(x)}{p_{\text {data }}(x)+p_g(x)}\right)+\int_x p_g(x) \log \left(\frac{p_g(x)}{p_{\text {data }}(x)+p_g(x)}\right)+\int_x p_g(x) \log 2+\int_x p_{\text {data }}(x) \log 2 \\ 
        &= -\log 4 + \int_x p_{\text {data }}(x) \log \left(2 \times \frac{p_{\text {data }}(x)}{p_{\text {data }} (x)+p_g(x)}\right)+\int_x p_g(x) \log \left(2 \times \frac{p_g(x)}{p_{\text {data }}(x)+p_g(x)}\right) \\ 
        &= -\log 4 + \int_x p_{\text {data }}(x) \log \left(\frac{p_{\text {data }}(x)}{\frac{p_{\text {data }}(x)+p_g(x)}{2}}\right)+\int_x p_g(x) \log \left(\frac{p_g(x)}{\frac{p_{\text {data }}(x)+p_g(x)}{2}}\right) \\
        &= -\log4+K L\left(p_{\text {data }} \| \frac{p_{\text {data }}+p_g}{2}\right)+K L\left(p_g \| \frac{p_{\text {data }}+p_g}{2}\right) \\
        &= -\log4 + 2. JSD(p_{data} \parallel p_g) \quad \text{; where JSD is the Jensen-Shannon Divergence}
    \end{aligned}
$$

When \(p_{data}(x) \approx p_g(x), JSD(p_{data} \parallel p_g) = 0\)

</p>

<p style="text-align: justify;">
    Therefore, we can see that the minimum point of this objective which is \(-log 4\) is indeed when \(p_{data}(x) \approx p_g(x)\). Hence 
    our optimal generator, which we get by minimizing this objective till its global minima, will end up mimicking the data distribution 
    through its generated outputs and our optimal discriminator \(D^*\) with will end up predicting for any image be it real or fake randomly 
    with a probability value of 0.5
</p>
<p><br></p>
</div>


<div style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<strong style="font-size: x-large;">References</strong>
<p style="text-align: justify;">[1] Jabbar, Abdul, Xi Li, and Bourahla Omar. "A survey on generative adversarial networks: Variants, applications, and training." ACM Computing Surveys (CSUR) 54.8 (2021): 1-49.</p>
<p style="text-align: justify;">[2] Goodfellow, Ian, et al. "Generative adversarial networks." Communications of the ACM 63.11 (2020): 139-144.</p>
<p style="text-align: justify;">[3] He, Kaiming, et al. "Deep residual learning for image recognition." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</p>
<p style="text-align: justify;">[4] Smolensky, Paul. "Information processing in dynamical systems: Foundations of harmony theory." (1986): 194-281.</p>
<p style="text-align: justify;">[5] Vincent, Pascal, et al. "Extracting and composing robust features with denoising autoencoders." Proceedings of the 25th international conference on Machine learning. 2008.</p>
<p style="text-align: justify;">[6] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18.7 (2006): 1527-1554.</p>
</div>


</body>
</html>